{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook describes the typical activities carried out  at the beginning to a project / thread when customer shares new data. We will be trying to understand the tables, columns and information flow. Typically we also look for data issues and confirm with respective owners for resolution. At the end of this activity, the data sources and their treatment is finalized. Code in this notebook will not be part of the production code.\n",
    "\n",
    "This data can be downloaded from\n",
    "[here](https://drive.google.com/file/d/11DqcBxxEcn3QA4YvPQmmExBm-m6AgUQ_/view?usp=sharing)\n",
    "\n",
    "**NOTE**:\n",
    "Download the data from the above link, and copy the extracted csv files to the path `data/raw/sales/` (relative to root of the code archive folder). Make sure to copy the files before continuing on with the rest of the notebook.\n",
    "\n",
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 64 µs, sys: 6 µs, total: 70 µs\n",
      "Wall time: 72.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Third-party imports\n",
    "import os.path as op\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "\n",
    "# Project imports\n",
    "from ta_lib.core.api import display_as_tabs, initialize_environment\n",
    "\n",
    "# Initialization\n",
    "initialize_environment(debug=False, hide_warnings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Background\n",
    "\n",
    "Customer is a distributor of electronic devices. They partner with manufacturers, carriers and refurbishers and sell across to  retailers. The selling price is the outcome of negotiation between sales representatives and retailers. Customer wants to understand the selling price variation and determine  optimal pricing with Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta_lib.core.api import create_context, list_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = op.join('conf', 'config.yml')\n",
    "context = create_context(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['/raw/housing', '/cleaned/housing', '/processed/housing', '/train/housing/features', '/train/housing/target', '/test/housing/features', '/test/housing/target', '/score/housing/output']"
      ],
      "text/plain": [
       "['/raw/housing',\n",
       " '/cleaned/housing',\n",
       " '/processed/housing',\n",
       " '/train/housing/features',\n",
       " '/train/housing/target',\n",
       " '/test/housing/features',\n",
       " '/test/housing/target',\n",
       " '/score/housing/output']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_datasets(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dataset key: data/raw/housing/housing.csv. \n\nAvailable datasets: ['/raw/housing', '/cleaned/housing', '/processed/housing', '/train/housing/features', '/train/housing/target', '/test/housing/features', '/test/housing/target', '/score/housing/output']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/regression-py/src/ta_lib/core/dataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(context, key, skip, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_catalog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"uri\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_uri_from_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"uri\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/regression-py/src/ta_lib/core/dataset.py\u001b[0m in \u001b[0;36m_get_val\u001b[0;34m(dct, key)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_tple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-42a0e65c2e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhousing_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/raw/housing/housing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/regression-py/src/ta_lib/core/dataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(context, key, skip, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mavlb_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;34mf\"Invalid dataset key: {key}. \\n\\nAvailable datasets: {avlb_keys}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dataset key: data/raw/housing/housing.csv. \n\nAvailable datasets: ['/raw/housing', '/cleaned/housing', '/processed/housing', '/train/housing/features', '/train/housing/target', '/test/housing/features', '/test/housing/target', '/score/housing/output']"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "housing_df = load_dataset(context, 'data/raw/housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "Given the raw data from data ingestion, we would now like to explore and learn more details about the data.\n",
    "\n",
    "\n",
    "The output of the step would be a summary report and discussion of any pertinent findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the eda API\n",
    "import ta_lib.eda.api as eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_as_tabs([('housing', housing_df.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_variable_summary(housing_df)\n",
    "\n",
    "display_as_tabs([('housing', sum)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "<details>\n",
    "1. Datatypes : We have both numeric and other types. The bulk of them seem to be numeric. `Numeric` is defined to be one of [float|int|date] and the rest are categorized as `Others`. A column is assumed to have `date` values if it has the string `date` in the column name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Plot\n",
    "\n",
    "Provides a high level summary of the dataset health.\n",
    "\n",
    "**Watch out for:**\n",
    "\n",
    "* too few numeric values\n",
    "* high % of missing values\n",
    "* high % of duplicate values\n",
    "* high % of duplicate columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum, plot1 = eda.get_data_health_summary(housing_df, return_plot=True)\n",
    "\n",
    "display_as_tabs([('housing', plot1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev NOTES**\n",
    "\n",
    "<details>\n",
    "1. Datatypes : We have both numeric and other types. The bulk of them seem to be numeric. `Numeric` is defined to be one of [float|int|date] and the rest are categorized as `Others`. A column is assumed to have `date` values if it has the string `date` in the column name.\n",
    "\n",
    "2. The missing value plot seems to indicate missing values are not present but we do have them. \n",
    "\n",
    "3. We are looking for duplicate observations (rows in the data). The plot shows the % of rows that are an exact replica of another row (using `df.duplicated`)\n",
    "\n",
    "4. We are looking for duplicate features (columns in the data).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values summary\n",
    "\n",
    "This provides an overall view focussing on amount of missing values in the dataset.\n",
    "\n",
    "**Watch out for:**\n",
    "* A few columns have significant number of missing values \n",
    "* Most columns have significant number of missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1, plot1 = eda.get_missing_values_summary(housing_df, return_plot=True)\n",
    "\n",
    "display_as_tabs([('housing', plot1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dev notes:**\n",
    "\n",
    "<details>\n",
    "    \n",
    "    * By default, the following are considered missing/NA values : `[np.Nan, pd.NaT, 'NA', None]`\n",
    "    * additional values can be passed to tigerml (add_additional_na_values)\n",
    "    * these are applied to all columns.\n",
    "    \n",
    "    * some of the above information can be learnt from the data discovery step (see discussion below)\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_duplicate_columns(housing_df)\n",
    "\n",
    "display_as_tabs([('housing', sum1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = eda.get_outliers(housing_df)\n",
    "\n",
    "display_as_tabs([('housing', sum1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Analysis report\n",
    "\n",
    "Generate a report that has all the above data in a single html. This could be useful to submit to a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ta_lib.reports.api import summary_report\n",
    "\n",
    "summary_report(housing_df, './housing.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
